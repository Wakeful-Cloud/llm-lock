{
  "goals": [
    {
      "goal": "action manipulation",
      "description": "An attacker coerces the assistant to retrieve and cite fabricated or misleading legal authorities, causing attorneys to rely on false precedent."
    },
    {
      "goal": "denial of service",
      "description": "A malicious user overwhelms the platform with a high volume of complex legal queries, degrading response times and making the service unusable for legitimate lawyers."
    },
    {
      "goal": "data exfiltration",
      "description": "The adversary attempts to extract confidential client information or privileged case details that the system processes or logs during research sessions."
    },
    {
      "goal": "prompt exfiltration",
      "description": "An attacker seeks to steal the internal prompt templates that shape the LLM's summarization and citation style, enabling replication of the proprietary workflow."
    },
    {
      "goal": "jailbreaking",
      "description": "The attacker tries to bypass safety controls to make the model produce illegal or unethical legal advice, such as how to evade liability or commit fraud."
    },
    {
      "goal": "action manipulation",
      "description": "The threat actor manipulates tool calls so the assistant accesses restricted or non\u2011public legal documents, exposing privileged material."
    },
    {
      "goal": "data exfiltration",
      "description": "A malicious actor extracts the curated bibliographies and citation lists generated for paying customers, stealing valuable research assets."
    }
  ]
}